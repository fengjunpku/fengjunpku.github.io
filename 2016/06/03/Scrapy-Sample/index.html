<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Scrapy_Sample | 熊窝</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="CentOS下安装
依赖：
1yum install libxslt-devel libxml2-devel python-devel libffi-devel

安装：
1pip install scrapy


Start_a_project1scrapy startproject &amp;lt;project_name&amp;gt;
如果项目名为weather12scrapy startproject">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy_Sample">
<meta property="og:url" content="http://fengjunpku.github.io/2016/06/03/Scrapy-Sample/index.html">
<meta property="og:site_name" content="熊窝">
<meta property="og:description" content="CentOS下安装
依赖：
1yum install libxslt-devel libxml2-devel python-devel libffi-devel

安装：
1pip install scrapy


Start_a_project1scrapy startproject &amp;lt;project_name&amp;gt;
如果项目名为weather12scrapy startproject">
<meta property="og:updated_time" content="2016-06-06T10:50:10.047Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy_Sample">
<meta name="twitter:description" content="CentOS下安装
依赖：
1yum install libxslt-devel libxml2-devel python-devel libffi-devel

安装：
1pip install scrapy


Start_a_project1scrapy startproject &amp;lt;project_name&amp;gt;
如果项目名为weather12scrapy startproject">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">熊窝</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">miaomiaoxiong.net</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://fengjunpku.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Scrapy-Sample" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/03/Scrapy-Sample/" class="article-date">
  <time datetime="2016-06-03T12:10:01.000Z" itemprop="datePublished">2016-06-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Scrapy_Sample
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="CentOS下安装"><a href="#CentOS下安装" class="headerlink" title="CentOS下安装"></a>CentOS下安装</h2><ul>
<li><p>依赖：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install libxslt-devel libxml2-devel python-devel libffi-devel</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Start-a-project"><a href="#Start-a-project" class="headerlink" title="Start_a_project"></a>Start_a_project</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &lt;project_name&gt;</span><br></pre></td></tr></table></figure>
<p>如果项目名为<code>weather</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject weather</span><br><span class="line">tree weather #列出目录结构</span><br></pre></td></tr></table></figure></p>
<p>文件分别是：<br>    <code>scrapy.cfg</code>: 项目的配置文件<br>    <code>weather/</code>: 该项目的python模块。之后将在此加入代码。<br>    <code>weather/items.py</code>: 项目中的item文件.<br>    <code>weather/pipelines.py</code>: 项目中的pipelines文件.<br>    <code>weather/settings.py</code>: 项目的设置文件.<br>    <code>weather/spiders/</code>: 放置spider代码的目录.</p>
<h2 id="Define-Item"><a href="#Define-Item" class="headerlink" title="Define_Item"></a>Define_Item</h2><p>Item 是保存爬取到的数据的容器；其使用方法和python字典类似，并且提供了额外保护机制来避免拼写错误导致的未定义字段错误。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># items.py</span><br><span class="line"># Define here the models for your scraped items</span><br><span class="line"># See documentation in:</span><br><span class="line"># http://doc.scrapy.org/en/latest/topics/items.html</span><br><span class="line">import scrapy</span><br><span class="line"> </span><br><span class="line">class WeatherItem(scrapy.Item):</span><br><span class="line">    # define the fields for your item here like:</span><br><span class="line">    # name = scrapy.Field()</span><br><span class="line">    # demo 1</span><br><span class="line">    city = scrapy.Field()</span><br><span class="line">    date = scrapy.Field()</span><br><span class="line">    dayDesc = scrapy.Field()</span><br><span class="line">    dayTemp = scrapy.Field()</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure></p>
<h2 id="Edit-Spider"><a href="#Edit-Spider" class="headerlink" title="Edit_Spider"></a>Edit_Spider</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Spider是用户编写用于从单个网站(或者一些网站)爬取数据的类。</p>
<p>其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 item 的方法。</p>
<p>为了创建一个Spider，必须继承 scrapy.Spider 类， 且定义以下三个属性:</p>
<ul>
<li><p><code>name</code>: 用于区别Spider。该名字必须是唯一的，您不可以为不同的Spider设定相同的名字。</p>
</li>
<li><p><code>start_urls</code>: 包含了Spider在启动时进行爬取的url列表。因此，第一个被获取到的页面将是其中之一。后续的URL则从初始的URL获取到的数据中提取。</p>
</li>
<li><p><code>parse()</code> 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。</p>
</li>
</ul>
<h3 id="分析网页"><a href="#分析网页" class="headerlink" title="分析网页"></a>分析网页</h3><p>页面源码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;h4 class=&quot;slider_ct_name&quot; id=&quot;slider_ct_name&quot;&gt;武汉&lt;/h4&gt;</span><br><span class="line">...</span><br><span class="line">&lt;div class=&quot;blk_fc_c0_scroll&quot; id=&quot;blk_fc_c0_scroll&quot; style=&quot;width: 1700px;&quot;&gt;</span><br><span class="line">    &lt;div class=&quot;blk_fc_c0_i&quot;&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_date&quot;&gt;01-28&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_day wt_fc_c0_i_today&quot;&gt;今天&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_icons clearfix&quot;&gt;</span><br><span class="line">            &lt;img class=&quot;icons0_wt png24&quot; src=&quot;http://www.sinaimg.cn/dy/weather/main/index14/007/icons_42_yl/w_04_27_00.png&quot; alt=&quot;雨夹雪&quot; title=&quot;雨夹雪&quot;&gt;</span><br><span class="line">            &lt;img class=&quot;icons0_wt png24&quot; src=&quot;http://www.sinaimg.cn/dy/weather/main/index14/007/icons_42_yl/w_04_29_01.png&quot; alt=&quot;中雪&quot; title=&quot;中雪&quot;&gt;</span><br><span class="line">        &lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_times&quot;&gt;</span><br><span class="line">            &lt;span class=&quot;wt_fc_c0_i_time&quot;&gt;白天&lt;/span&gt;</span><br><span class="line">            &lt;span class=&quot;wt_fc_c0_i_time&quot;&gt;夜间&lt;/span&gt;</span><br><span class="line">        &lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_temp&quot;&gt;1°C / -2°C&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_tip&quot;&gt;北风 3～4级&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_tip&quot;&gt;无持续风向 小于3级&lt;/p&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">    &lt;div class=&quot;blk_fc_c0_i&quot;&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_date&quot;&gt;01-29&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_day &quot;&gt;星期四&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_icons clearfix&quot;&gt;</span><br><span class="line">            &lt;img class=&quot;icons0_wt png24&quot; src=&quot;http://www.sinaimg.cn/dy/weather/main/index14/007/icons_42_yl/w_04_29_00.png&quot; alt=&quot;中雪&quot; title=&quot;中雪&quot;&gt;</span><br><span class="line">            &lt;img class=&quot;icons0_wt png24&quot; src=&quot;http://www.sinaimg.cn/dy/weather/main/index14/007/icons_42_yl/w_07_25_01.png&quot; alt=&quot;阴&quot; title=&quot;阴&quot;&gt;</span><br><span class="line">        &lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_times&quot;&gt;</span><br><span class="line">            &lt;span class=&quot;wt_fc_c0_i_time&quot;&gt;白天&lt;/span&gt;</span><br><span class="line">            &lt;span class=&quot;wt_fc_c0_i_time&quot;&gt;夜间&lt;/span&gt;</span><br><span class="line">        &lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_temp&quot;&gt;1°C / -2°C&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;wt_fc_c0_i_tip&quot;&gt;无持续风向 小于3级&lt;/p&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">    ...</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure></p>
<p>有如下目标：</p>
<ul>
<li>城市名可以通过获取id为slider_ct_name的h4元素获取</li>
<li>日期可以通过获取id为blk_fc_c0_scroll下的class为wt_fc_c0_i_date的p元素获取</li>
<li>天气描述可以通过获取id为blk_fc_c0_scroll下的class为icons0_wt的img元素获取</li>
<li>温度可以通过获取id为blk_fc_c0_scroll下的class为wt_fc_c0_i_temp的p元素获取<h3 id="Spider"><a href="#Spider" class="headerlink" title="Spider"></a>Spider</h3>因此，我们的Spider代码如下，保存在<code>weather/spiders</code>目录下的<code>localweather.py</code> 文件中:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import scrapy</span><br><span class="line">from weather.items import WeatherItem</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class WeatherSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;myweather&quot;</span><br><span class="line">    allowed_domains = [&quot;sina.com.cn&quot;]</span><br><span class="line">    start_urls = [&apos;http://weather.sina.com.cn&apos;]</span><br><span class="line"> </span><br><span class="line">    def parse(self, response):</span><br><span class="line">        item = WeatherItem()</span><br><span class="line">        item[&apos;city&apos;] = response.xpath(&apos;//*[@id=&quot;slider_ct_name&quot;]/text()&apos;).extract()</span><br><span class="line">        tenDay = response.xpath(&apos;//*[@id=&quot;blk_fc_c0_scroll&quot;]&apos;);</span><br><span class="line">        item[&apos;date&apos;] = tenDay.css(&apos;p.wt_fc_c0_i_date::text&apos;).extract()</span><br><span class="line">        item[&apos;dayDesc&apos;] = tenDay.css(&apos;img.icons0_wt::attr(title)&apos;).extract()</span><br><span class="line">        item[&apos;dayTemp&apos;] = tenDay.css(&apos;p.wt_fc_c0_i_temp::text&apos;).extract()</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>代码中的xpath和css后面括号的内容为选择器，关于xpath和css选择器的内容可参考<a href="http://doc.scrapy.org/en/0.24/topics/selectors.html" target="_blank" rel="external">官方教程</a></p>
<h3 id="递归爬取"><a href="#递归爬取" class="headerlink" title="递归爬取"></a>递归爬取</h3><p>将<code>spider</code>类写成<code>request</code>的生成器，比如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class spider(scrapy.Spider):</span><br><span class="line">    ...</span><br><span class="line">    yield self.make_requests_from_url(url)</span><br><span class="line">    yield item</span><br></pre></td></tr></table></figure></p>
<h2 id="Run-Spider"><a href="#Run-Spider" class="headerlink" title="Run_Spider"></a>Run_Spider</h2><p>在项目的scrapy.cfg文件同级目录运行命令，下同）中运行下面的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#运行名字为 myweather 的爬虫，然后把结果以json格式保存在wea.json文件中(数据是以unicode方式编码的)</span><br><span class="line">scrapy crawl myweather -o wea.json</span><br></pre></td></tr></table></figure></p>
<h2 id="Save-Data"><a href="#Save-Data" class="headerlink" title="Save_Data"></a>Save_Data</h2><h3 id="Edit-pipeline"><a href="#Edit-pipeline" class="headerlink" title="Edit_pipeline"></a>Edit_pipeline</h3><p>上面只是把数据保存在json文件中了，如果我们想自己保存在文件或数据库中，如何操作呢？</p>
<p>这里就要用到 Item Pipeline 了，那么 Item Pipeline 是什么呢？</p>
<p>当Item在Spider中被收集之后，它将会被传递到Item Pipeline中，一些组件会按照一定的顺序执行对Item的处理。</p>
<p>每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。</p>
<p>item pipeline的典型应用有：</p>
<ul>
<li>清理HTML数据</li>
<li>验证爬取的数据(检查item包含某些字段)</li>
<li>查重(并丢弃)</li>
<li>将爬取结果保存到文件或数据库中</li>
<li>每个item pipeline组件都需要调用 process_item 方法，这个方法必须返回一个 Item (或任何继承类)对象， 或是抛出 DropItem异常，被丢弃的item将不会被之后的pipeline组件所处理。</li>
</ul>
<p>我们这里把数据转码后保存在<code>wea.txt</code>文本中。</p>
<p><code>pipelines.py</code>文件在创建项目时已经自动被创建好了，我们在其中加上保存到文件的代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"> </span><br><span class="line"># Define your item pipelines here</span><br><span class="line">#</span><br><span class="line"># Don&apos;t forget to add your pipeline to the ITEM_PIPELINES setting</span><br><span class="line"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class WeatherPipeline(object):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        pass</span><br><span class="line"> </span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        with open(&apos;wea.txt&apos;, &apos;w+&apos;) as file:</span><br><span class="line">            city = item[&apos;city&apos;][0].encode(&apos;utf-8&apos;)</span><br><span class="line">            file.write(&apos;city:&apos; + str(city) + &apos;\n\n&apos;)</span><br><span class="line"> </span><br><span class="line">            date = item[&apos;date&apos;]</span><br><span class="line"> </span><br><span class="line">            desc = item[&apos;dayDesc&apos;]</span><br><span class="line">            dayDesc = desc[1::2]</span><br><span class="line">            nightDesc = desc[0::2]</span><br><span class="line"> </span><br><span class="line">            dayTemp = item[&apos;dayTemp&apos;]</span><br><span class="line"> </span><br><span class="line">            weaitem = zip(date, dayDesc, nightDesc, dayTemp)</span><br><span class="line"> </span><br><span class="line">            for i in range(len(weaitem)):</span><br><span class="line">                item = weaitem[i]</span><br><span class="line">                d = item[0]</span><br><span class="line">                dd = item[1]</span><br><span class="line">                nd = item[2]</span><br><span class="line">                ta = item[3].split(&apos;/&apos;)</span><br><span class="line">                dt = ta[0]</span><br><span class="line">                nt = ta[1]</span><br><span class="line">                txt = &apos;date:&#123;0&#125;\t\tday:&#123;1&#125;(&#123;2&#125;)\t\tnight:&#123;3&#125;(&#123;4&#125;)\n\n&apos;.format(</span><br><span class="line">                    d,</span><br><span class="line">                    dd.encode(&apos;utf-8&apos;),</span><br><span class="line">                    dt.encode(&apos;utf-8&apos;),</span><br><span class="line">                    nd.encode(&apos;utf-8&apos;),</span><br><span class="line">                    nt.encode(&apos;utf-8&apos;)</span><br><span class="line">                )</span><br><span class="line">                file.write(txt)</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure></p>
<h3 id="Configure-pipeline"><a href="#Configure-pipeline" class="headerlink" title="Configure_pipeline"></a>Configure_pipeline</h3><p>写好ITEM_PIPELINES后，还有很重要的一步，就是把 ITEM_PIPELINES 添加到设置文件<code>settings.py</code>中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    &apos;weather.pipelines.WeatherPipeline&apos;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>还可以在设置中修改一下爬虫的 USER_AGENT 和 Referer 信息，增加爬虫请求的时间间隔。整个 settings.py 文件内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"> </span><br><span class="line"># Scrapy settings for weather project</span><br><span class="line">#</span><br><span class="line"># For simplicity, this file contains only the most important settings by</span><br><span class="line"># default. All the other settings are documented here:</span><br><span class="line">#</span><br><span class="line">#     http://doc.scrapy.org/en/latest/topics/settings.html</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">BOT_NAME = &apos;Googlebot&apos;</span><br><span class="line"> </span><br><span class="line">SPIDER_MODULES = [&apos;weather.spiders&apos;]</span><br><span class="line">NEWSPIDER_MODULE = &apos;weather.spiders&apos;</span><br><span class="line"> </span><br><span class="line"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span><br><span class="line">#USER_AGENT = &apos;weather (+http://www.yourdomain.com)&apos;</span><br><span class="line">USER_AGENT = &apos;User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36&apos;</span><br><span class="line"> </span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    &apos;Referer&apos;: &apos;http://www.weibo.com&apos;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    &apos;weather.pipelines.WeatherPipeline&apos;: 1</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">DOWNLOAD_DELAY = 0.5</span><br></pre></td></tr></table></figure></p>
<h2 id="Run-Again"><a href="#Run-Again" class="headerlink" title="Run_Again"></a>Run_Again</h2><p>在项目的scrapy.cfg同级目录下用下面的命令运行爬虫：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl myweather</span><br></pre></td></tr></table></figure></p>
<h2 id="Parser-with-BeautifulSoup"><a href="#Parser-with-BeautifulSoup" class="headerlink" title="Parser_with_BeautifulSoup"></a>Parser_with_BeautifulSoup</h2><p>改进<code>WeatherSpider</code>代码:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># localweather.py</span><br><span class="line">import scrapy</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">from weather.items import WeatherItem</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class WeatherSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;myweather&quot;</span><br><span class="line">    allowed_domains = [&quot;sina.com.cn&quot;]</span><br><span class="line">    start_urls = [&apos;http://weather.sina.com.cn&apos;]</span><br><span class="line"> </span><br><span class="line">    def parse(self, response):</span><br><span class="line">        html_doc = response.body</span><br><span class="line">        #html_doc = html_doc.decode(&apos;utf-8&apos;)</span><br><span class="line">        soup = BeautifulSoup(html_doc)</span><br><span class="line">        itemTemp = &#123;&#125;</span><br><span class="line">        itemTemp[&apos;city&apos;] = soup.find(id=&apos;slider_ct_name&apos;)</span><br><span class="line">        tenDay = soup.find(id=&apos;blk_fc_c0_scroll&apos;)</span><br><span class="line">        itemTemp[&apos;date&apos;] = tenDay.findAll(&quot;p&quot;, &#123;&quot;class&quot;: &apos;wt_fc_c0_i_date&apos;&#125;)</span><br><span class="line">        itemTemp[&apos;dayDesc&apos;] = tenDay.findAll(&quot;img&quot;, &#123;&quot;class&quot;: &apos;icons0_wt&apos;&#125;)</span><br><span class="line">        itemTemp[&apos;dayTemp&apos;] = tenDay.findAll(&apos;p&apos;, &#123;&quot;class&quot;: &apos;wt_fc_c0_i_temp&apos;&#125;)</span><br><span class="line">        item = WeatherItem()</span><br><span class="line">        for att in itemTemp:</span><br><span class="line">            item[att] = []</span><br><span class="line">            if att == &apos;city&apos;:</span><br><span class="line">                item[att] = itemTemp.get(att).text</span><br><span class="line">                continue</span><br><span class="line">            for obj in itemTemp.get(att):</span><br><span class="line">                if att == &apos;dayDesc&apos;:</span><br><span class="line">                    item[att].append(obj[&apos;title&apos;])</span><br><span class="line">                else:</span><br><span class="line">                    item[att].append(obj.text)</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://fengjunpku.github.io/2016/06/03/Scrapy-Sample/" data-id="cip8e4fpf0003jwms8fcbqq2d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/06/03/Untitle-20160603/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          无题
        
      </div>
    </a>
  
  
    <a href="/2016/06/02/bloom-filter/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Bloom-Filter</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/c/" style="font-size: 10px;">c++</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/mood/" style="font-size: 15px;">mood</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/scrapy/" style="font-size: 10px;">scrapy</a> <a href="/tags/web/" style="font-size: 10px;">web</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/06/09/summary-of-scraping-by-python/">python爬虫总结</a>
          </li>
        
          <li>
            <a href="/2016/06/04/install-python3/">Centos安装python3</a>
          </li>
        
          <li>
            <a href="/2016/06/03/poem-at-nangjing/">金陵春夜</a>
          </li>
        
          <li>
            <a href="/2016/06/03/Untitle-20160603/">无题</a>
          </li>
        
          <li>
            <a href="/2016/06/03/Scrapy-Sample/">Scrapy_Sample</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Miaomiaoxiong<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>